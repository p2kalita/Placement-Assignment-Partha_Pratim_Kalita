{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4493c76e",
   "metadata": {},
   "source": [
    "### Question 3: Train a Pure CNN with less than 10000 trainable parameters using the MNIST Dataset having minimum validation accuracy of 99.40%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791b4ae2-c307-4261-98c3-c59c0a534e73",
   "metadata": {},
   "source": [
    "### Tensorflow Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9171da31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense,Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape and normalize input data\n",
    "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "# One-hot encode the target labels\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Define the CNN architecture\n",
    "model = Sequential([\n",
    "    Conv2D(8, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(16, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "#    Dropout(0.5),\n",
    "    Flatten(),\n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe7af7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 8)         80        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 16)        1168      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 5, 5, 16)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 400)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                8020      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,478\n",
      "Trainable params: 9,478\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b99dac7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4254 - accuracy: 0.8634 - val_loss: 0.1029 - val_accuracy: 0.9701\n",
      "Epoch 2/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1621 - accuracy: 0.9500 - val_loss: 0.0669 - val_accuracy: 0.9788\n",
      "Epoch 3/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1312 - accuracy: 0.9589 - val_loss: 0.0560 - val_accuracy: 0.9841\n",
      "Epoch 4/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1148 - accuracy: 0.9646 - val_loss: 0.0459 - val_accuracy: 0.9852\n",
      "Epoch 5/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1072 - accuracy: 0.9673 - val_loss: 0.0419 - val_accuracy: 0.9879\n",
      "Epoch 6/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1014 - accuracy: 0.9686 - val_loss: 0.0408 - val_accuracy: 0.9875\n",
      "Epoch 7/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0955 - accuracy: 0.9698 - val_loss: 0.0378 - val_accuracy: 0.9887\n",
      "Epoch 8/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0918 - accuracy: 0.9718 - val_loss: 0.0382 - val_accuracy: 0.9887\n",
      "Epoch 9/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0849 - accuracy: 0.9734 - val_loss: 0.0341 - val_accuracy: 0.9897\n",
      "Epoch 10/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0836 - accuracy: 0.9732 - val_loss: 0.0336 - val_accuracy: 0.9894\n",
      "Epoch 11/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0832 - accuracy: 0.9736 - val_loss: 0.0364 - val_accuracy: 0.9881\n",
      "Epoch 12/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0764 - accuracy: 0.9758 - val_loss: 0.0312 - val_accuracy: 0.9897\n",
      "Epoch 13/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0765 - accuracy: 0.9758 - val_loss: 0.0353 - val_accuracy: 0.9885\n",
      "Epoch 14/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0745 - accuracy: 0.9764 - val_loss: 0.0303 - val_accuracy: 0.9906\n",
      "Epoch 15/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0718 - accuracy: 0.9772 - val_loss: 0.0295 - val_accuracy: 0.9898\n",
      "Epoch 16/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0698 - accuracy: 0.9783 - val_loss: 0.0282 - val_accuracy: 0.9903\n",
      "Epoch 17/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0683 - accuracy: 0.9780 - val_loss: 0.0270 - val_accuracy: 0.9902\n",
      "Epoch 18/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0679 - accuracy: 0.9791 - val_loss: 0.0259 - val_accuracy: 0.9912\n",
      "Epoch 19/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0656 - accuracy: 0.9796 - val_loss: 0.0281 - val_accuracy: 0.9912\n",
      "Epoch 20/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0662 - accuracy: 0.9788 - val_loss: 0.0273 - val_accuracy: 0.9906\n",
      "Epoch 21/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0633 - accuracy: 0.9802 - val_loss: 0.0271 - val_accuracy: 0.9915\n",
      "Epoch 22/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0632 - accuracy: 0.9797 - val_loss: 0.0252 - val_accuracy: 0.9915\n",
      "Epoch 23/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0629 - accuracy: 0.9802 - val_loss: 0.0245 - val_accuracy: 0.9923\n",
      "Epoch 24/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0624 - accuracy: 0.9797 - val_loss: 0.0245 - val_accuracy: 0.9917\n",
      "Epoch 25/25\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0608 - accuracy: 0.9813 - val_loss: 0.0242 - val_accuracy: 0.9920\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0242 - accuracy: 0.9920\n",
      "Test Accuracy: 99.19999837875366\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=25, batch_size=32, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "_, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Test Accuracy:\", accuracy*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89770b32",
   "metadata": {},
   "source": [
    "### Pytorch Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9640b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25: Train Loss: 724.1251, Train Acc: 84.61%, Val Loss: 50.9466, Val Acc: 96.24%\n",
      "Epoch 2/25: Train Loss: 320.7783, Train Acc: 93.36%, Val Loss: 38.0851, Val Acc: 97.05%\n",
      "Epoch 3/25: Train Loss: 264.5749, Train Acc: 94.45%, Val Loss: 32.8299, Val Acc: 97.37%\n",
      "Epoch 4/25: Train Loss: 235.4968, Train Acc: 95.10%, Val Loss: 27.4179, Val Acc: 97.88%\n",
      "Epoch 5/25: Train Loss: 225.5769, Train Acc: 95.34%, Val Loss: 26.1155, Val Acc: 97.97%\n",
      "Epoch 6/25: Train Loss: 213.9495, Train Acc: 95.51%, Val Loss: 25.8241, Val Acc: 97.98%\n",
      "Epoch 7/25: Train Loss: 198.3514, Train Acc: 95.89%, Val Loss: 24.2367, Val Acc: 97.92%\n",
      "Epoch 8/25: Train Loss: 191.2112, Train Acc: 96.03%, Val Loss: 23.0530, Val Acc: 98.05%\n",
      "Epoch 9/25: Train Loss: 180.1479, Train Acc: 96.21%, Val Loss: 20.9298, Val Acc: 98.26%\n",
      "Epoch 10/25: Train Loss: 166.4154, Train Acc: 96.40%, Val Loss: 23.4028, Val Acc: 98.22%\n",
      "Epoch 11/25: Train Loss: 170.7314, Train Acc: 96.45%, Val Loss: 19.7236, Val Acc: 98.42%\n",
      "Epoch 12/25: Train Loss: 163.4942, Train Acc: 96.53%, Val Loss: 19.0068, Val Acc: 98.36%\n",
      "Epoch 13/25: Train Loss: 156.5759, Train Acc: 96.75%, Val Loss: 18.3546, Val Acc: 98.53%\n",
      "Epoch 14/25: Train Loss: 149.6918, Train Acc: 96.82%, Val Loss: 19.6701, Val Acc: 98.35%\n",
      "Epoch 15/25: Train Loss: 150.8680, Train Acc: 96.84%, Val Loss: 18.2137, Val Acc: 98.58%\n",
      "Epoch 16/25: Train Loss: 145.5484, Train Acc: 96.93%, Val Loss: 18.0195, Val Acc: 98.53%\n",
      "Epoch 17/25: Train Loss: 140.2033, Train Acc: 97.08%, Val Loss: 17.0342, Val Acc: 98.53%\n",
      "Epoch 18/25: Train Loss: 138.0703, Train Acc: 97.05%, Val Loss: 17.4555, Val Acc: 98.58%\n",
      "Epoch 19/25: Train Loss: 135.2139, Train Acc: 97.22%, Val Loss: 17.1827, Val Acc: 98.62%\n",
      "Epoch 20/25: Train Loss: 130.4059, Train Acc: 97.23%, Val Loss: 16.6013, Val Acc: 98.62%\n",
      "Epoch 21/25: Train Loss: 127.6658, Train Acc: 97.28%, Val Loss: 16.8896, Val Acc: 98.73%\n",
      "Epoch 22/25: Train Loss: 127.6625, Train Acc: 97.29%, Val Loss: 16.8514, Val Acc: 98.71%\n",
      "Epoch 23/25: Train Loss: 123.8151, Train Acc: 97.37%, Val Loss: 15.4348, Val Acc: 98.71%\n",
      "Epoch 24/25: Train Loss: 122.9563, Train Acc: 97.41%, Val Loss: 16.2617, Val Acc: 98.72%\n",
      "Epoch 25/25: Train Loss: 121.7800, Train Acc: 97.46%, Val Loss: 16.5429, Val Acc: 98.69%\n",
      "Test Accuracy: 98.75%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load MNIST dataset\n",
    "train_dataset = MNIST(root=\"./data\", train=True, download=True, transform=ToTensor())\n",
    "test_dataset = MNIST(root=\"./data\", train=False, download=True, transform=ToTensor())\n",
    "\n",
    "# Define indices for train-validation split\n",
    "num_samples = len(train_dataset)\n",
    "indices = list(range(num_samples))\n",
    "split = int(0.8 * num_samples)  # 80% train, 20% validation\n",
    "train_indices, val_indices = indices[:split], indices[split:]\n",
    "\n",
    "# Create data loaders\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, sampler=train_sampler)\n",
    "val_loader = DataLoader(train_dataset, batch_size=32, sampler=val_sampler)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# Define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, stride=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, stride=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 20)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create the model instance\n",
    "model = Net().to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 25\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_acc = 100.0 * train_correct / len(train_indices)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_acc = 100.0 * val_correct / len(val_indices)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    # Save the model with the best validation accuracy\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")\n",
    "\n",
    "# Load the best model weights\n",
    "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "test_correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_acc = 100.0 * test_correct / len(test_dataset)\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
