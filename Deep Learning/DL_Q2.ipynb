{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06013102",
   "metadata": {},
   "source": [
    "### Question 2 : Implement 5 different CNN architectures with a comparison table for CIFAR 10 dataset using the PyTorch library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "452e4f98",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             448\n",
      "              ReLU-2           [-1, 16, 32, 32]               0\n",
      "         MaxPool2d-3           [-1, 16, 16, 16]               0\n",
      "            Conv2d-4           [-1, 32, 16, 16]           4,640\n",
      "              ReLU-5           [-1, 32, 16, 16]               0\n",
      "         MaxPool2d-6             [-1, 32, 8, 8]               0\n",
      "            Linear-7                   [-1, 10]          20,490\n",
      "================================================================\n",
      "Total params: 25,578\n",
      "Trainable params: 25,578\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.42\n",
      "Params size (MB): 0.10\n",
      "Estimated Total Size (MB): 0.53\n",
      "----------------------------------------------------------------\n",
      "Training started for NET1\n",
      "\n",
      "[1,   200] loss: 2.238\n",
      "[2,   200] loss: 2.004\n",
      "[3,   200] loss: 1.849\n",
      "[4,   200] loss: 1.737\n",
      "[5,   200] loss: 1.672\n",
      "[6,   200] loss: 1.602\n",
      "[7,   200] loss: 1.562\n",
      "[8,   200] loss: 1.516\n",
      "[9,   200] loss: 1.485\n",
      "[10,   200] loss: 1.465\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 32, 32]             224\n",
      "              ReLU-2            [-1, 8, 32, 32]               0\n",
      "         MaxPool2d-3            [-1, 8, 16, 16]               0\n",
      "            Conv2d-4           [-1, 16, 16, 16]           1,168\n",
      "              ReLU-5           [-1, 16, 16, 16]               0\n",
      "         MaxPool2d-6             [-1, 16, 8, 8]               0\n",
      "            Linear-7                  [-1, 256]         262,400\n",
      "              ReLU-8                  [-1, 256]               0\n",
      "            Linear-9                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 266,362\n",
      "Trainable params: 266,362\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.21\n",
      "Params size (MB): 1.02\n",
      "Estimated Total Size (MB): 1.24\n",
      "----------------------------------------------------------------\n",
      "Training started for NET2\n",
      "\n",
      "[1,   200] loss: 2.299\n",
      "[2,   200] loss: 2.228\n",
      "[3,   200] loss: 2.042\n",
      "[4,   200] loss: 1.976\n",
      "[5,   200] loss: 1.912\n",
      "[6,   200] loss: 1.827\n",
      "[7,   200] loss: 1.733\n",
      "[8,   200] loss: 1.653\n",
      "[9,   200] loss: 1.610\n",
      "[10,   200] loss: 1.579\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 32, 32]             224\n",
      "              ReLU-2            [-1, 8, 32, 32]               0\n",
      "            Conv2d-3           [-1, 16, 32, 32]           1,168\n",
      "              ReLU-4           [-1, 16, 32, 32]               0\n",
      "            Linear-5                  [-1, 256]       4,194,560\n",
      "              ReLU-6                  [-1, 256]               0\n",
      "            Linear-7                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 4,198,522\n",
      "Trainable params: 4,198,522\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.38\n",
      "Params size (MB): 16.02\n",
      "Estimated Total Size (MB): 16.41\n",
      "----------------------------------------------------------------\n",
      "Training started for NET3\n",
      "\n",
      "[1,   200] loss: 2.185\n",
      "[2,   200] loss: 1.904\n",
      "[3,   200] loss: 1.807\n",
      "[4,   200] loss: 1.732\n",
      "[5,   200] loss: 1.660\n",
      "[6,   200] loss: 1.589\n",
      "[7,   200] loss: 1.534\n",
      "[8,   200] loss: 1.494\n",
      "[9,   200] loss: 1.466\n",
      "[10,   200] loss: 1.441\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 32, 32]             608\n",
      "              ReLU-2            [-1, 8, 32, 32]               0\n",
      "         MaxPool2d-3            [-1, 8, 16, 16]               0\n",
      "            Conv2d-4           [-1, 16, 16, 16]           3,216\n",
      "              ReLU-5           [-1, 16, 16, 16]               0\n",
      "         MaxPool2d-6             [-1, 16, 8, 8]               0\n",
      "            Linear-7                  [-1, 256]         262,400\n",
      "              ReLU-8                  [-1, 256]               0\n",
      "            Linear-9                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 268,794\n",
      "Trainable params: 268,794\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.21\n",
      "Params size (MB): 1.03\n",
      "Estimated Total Size (MB): 1.25\n",
      "----------------------------------------------------------------\n",
      "Training started for NET4\n",
      "\n",
      "[1,   200] loss: 2.294\n",
      "[2,   200] loss: 2.091\n",
      "[3,   200] loss: 1.969\n",
      "[4,   200] loss: 1.886\n",
      "[5,   200] loss: 1.800\n",
      "[6,   200] loss: 1.696\n",
      "[7,   200] loss: 1.626\n",
      "[8,   200] loss: 1.556\n",
      "[9,   200] loss: 1.515\n",
      "[10,   200] loss: 1.488\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 32, 32]             224\n",
      "              ReLU-2            [-1, 8, 32, 32]               0\n",
      "            Conv2d-3            [-1, 8, 32, 32]             584\n",
      "              ReLU-4            [-1, 8, 32, 32]               0\n",
      "            Linear-5                  [-1, 256]       2,097,408\n",
      "              ReLU-6                  [-1, 256]               0\n",
      "            Linear-7                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 2,100,786\n",
      "Trainable params: 2,100,786\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.25\n",
      "Params size (MB): 8.01\n",
      "Estimated Total Size (MB): 8.28\n",
      "----------------------------------------------------------------\n",
      "Training started for NET5\n",
      "\n",
      "[1,   200] loss: 2.277\n",
      "[2,   200] loss: 2.023\n",
      "[3,   200] loss: 1.876\n",
      "[4,   200] loss: 1.768\n",
      "[5,   200] loss: 1.676\n",
      "[6,   200] loss: 1.607\n",
      "[7,   200] loss: 1.560\n",
      "[8,   200] loss: 1.510\n",
      "[9,   200] loss: 1.474\n",
      "[10,   200] loss: 1.443\n",
      "\n",
      "\n",
      "Accuracy 1: 53.4\n",
      "Accuracy 2: 47.67\n",
      "Accuracy 3: 52.38\n",
      "Accuracy 4: 49.93\n",
      "Accuracy 5: 51.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "\n",
    "# Define the transformations for data preprocessing\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# Define data loaders\n",
    "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "# CNN architecture 1\n",
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc = nn.Linear(32 * 8 * 8, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu1(self.conv1(x)))\n",
    "        x = self.pool(self.relu2(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# CNN architecture 2\n",
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(16 * 8 * 8, 256)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# CNN architecture 3\n",
    "class Net3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(16 * 32 * 32, 256)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.relu2(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# CNN architecture 4\n",
    "class Net4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net4, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, 5, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 5, padding=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(16 * 8 * 8, 256)  \n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# CNN architecture 5\n",
    "class Net5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net5, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 8, 3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(8 * 32 * 32, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Initialize the networks\n",
    "net1 = Net1()\n",
    "net2 = Net2()\n",
    "net3 = Net3()\n",
    "net4 = Net4()\n",
    "net5 = Net5()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer1 = optim.SGD(net1.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer2 = optim.SGD(net2.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer3 = optim.SGD(net3.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer4 = optim.SGD(net4.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer5 = optim.SGD(net5.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "def get_variable_name(var):\n",
    "    variables = globals()\n",
    "    \n",
    "    for name, value in variables.items():\n",
    "        if value is var:\n",
    "            return name\n",
    "\n",
    "# Train the networks\n",
    "def train(net, optimizer, trainloader):\n",
    "    var = get_variable_name(net)\n",
    "    print(f\"Training started for {str.upper(var)}\\n\")\n",
    "    net.train()\n",
    "    for epoch in range(10):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 200 == 199:\n",
    "                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 200))\n",
    "                running_loss = 0.0\n",
    "    print('\\n')\n",
    "    \n",
    "# Test the networks\n",
    "def test(net, testloader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "#Train and test the networks\n",
    "summary(net1, (3, 32, 32))\n",
    "train(net1, optimizer1, trainloader)\n",
    "\n",
    "summary(net2, (3, 32, 32))\n",
    "train(net2, optimizer2, trainloader)\n",
    "\n",
    "summary(net3, (3, 32, 32))\n",
    "train(net3, optimizer3, trainloader)\n",
    "\n",
    "summary(net4, (3, 32, 32))\n",
    "train(net4, optimizer4, trainloader)\n",
    "\n",
    "summary(net5, (3, 32, 32))\n",
    "train(net5, optimizer5, trainloader)\n",
    "\n",
    "accuracy1 = test(net1, testloader)\n",
    "accuracy2 = test(net2, testloader)\n",
    "accuracy3 = test(net3, testloader)\n",
    "accuracy4 = test(net4, testloader)\n",
    "accuracy5 = test(net5, testloader)\n",
    "\n",
    "print(\"Accuracy 1:\", accuracy1)\n",
    "print(\"Accuracy 2:\", accuracy2)\n",
    "print(\"Accuracy 3:\", accuracy3)\n",
    "print(\"Accuracy 4:\", accuracy4)\n",
    "print(\"Accuracy 5:\", accuracy5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
